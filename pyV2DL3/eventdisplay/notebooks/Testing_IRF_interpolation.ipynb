{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline --no-import-all\n",
    "\n",
    "from ctypes import c_float\n",
    "import sys\n",
    "\n",
    "# import numpy as np\n",
    "from astropy.io import fits\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "\n",
    "# from ROOT import gSystem, TFile, TCanvas, TGraphAsymmErrors, TH1D, TH2D, TGraphAsymmErrors, TProfile\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from root_numpy import hist2array\n",
    "\n",
    "# from ROOT import VARootIO, VAEffectiveAreaManager, VAEASimpleParameterData\n",
    "# if gSystem.Load(\"$EVNDISPSYS/lib/libVAnaSum.so\"):\n",
    "#     print(\"Problem loading EventDisplay libraries - please check this before proceeding\")\n",
    "    \n",
    "# from ROOT import VInstrumentResponseFunctionData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here most of the functions used to read the effective area file and convert ROOT histograms to numpy arrays.\n",
    "\n",
    "It's a complete mess, but if you want, I can try to document it a bit (more)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicities(array, atol):\n",
    "    i = 0\n",
    "    while(i < len(array)-1):\n",
    "        i += 1\n",
    "        if np.isclose(array[i-1], array[i], atol=atol):\n",
    "            array = np.delete(array,i-1)\n",
    "            i -= 1\n",
    "    return array\n",
    "\n",
    "def graph_to_array_y(graph):\n",
    "    y = [g for g in graph.GetY()]\n",
    "    return y\n",
    "\n",
    "def graph_to_array_x(graph):\n",
    "    x = [g for g in graph.GetX()]\n",
    "    return x\n",
    "\n",
    "def bin_edges_to_centers(axis):\n",
    "    # This function assumes bins of equal width\n",
    "    bin_size = axis[1]-axis[0]\n",
    "    return np.delete(axis + bin_size/2., len(axis)-1)\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def extract_irf(filename, irf_name, coord_tuple=False, return_irf_axes=False): \n",
    "    # Get both the ROOT effective area TTree and the uproot one (much faster)\n",
    "    effAreaFile = TFile.Open(filename)\n",
    "    effAreaTree = effAreaFile.Get(\"fEffArea\")\n",
    "    fast_effArea = uproot.open(filename)['fEffArea']\n",
    "\n",
    "    # Load parameters from each TTree on arrays with uproot (super fast)\n",
    "    all_zds = fast_effArea.array('ze')\n",
    "    all_azs = fast_effArea.array('az')\n",
    "    all_azMins = fast_effArea.array('azMin')\n",
    "    all_azMaxs = fast_effArea.array('azMax')\n",
    "    all_Woffs = fast_effArea.array('Woff')\n",
    "    all_pedvars = fast_effArea.array('pedvar')\n",
    "    all_indexs = fast_effArea.array('index')\n",
    "    all_nbins =  fast_effArea.array('nbins')\n",
    "    all_rec_nbins =  fast_effArea.array('Rec_nbins')\n",
    "    \n",
    "    # If no coord_tuple is provided, extract the IRF over all dimensions\n",
    "    azs = indexs = pedvars = zds = woffs = []\n",
    "    if not coord_tuple:\n",
    "        zds, zes_counts = np.unique(np.round(fast_effArea.array('ze'), decimals=2), return_counts=True)\n",
    "        azs = np.unique(fast_effArea.array('az'))\n",
    "        woffs, Woffs_counts = np.unique(np.round(fast_effArea.array('Woff'), decimals=2), return_counts=True)\n",
    "        pedvars, pedvars_counts = np.unique(np.round(fast_effArea.array('pedvar'), decimals=2), return_counts=True)\n",
    "        indexs, indexs_counts = np.unique(np.round(fast_effArea.array('index'), decimals=2), return_counts=True)\n",
    "        # IMPORTANT: Remove duplicities (shouldn't be the case, but the values are not stored properly...)\n",
    "        # We remove the duplicities from the zenith and pedestal values arrays:\n",
    "        zds = remove_duplicities(zds, 2.0)\n",
    "        pedvars = remove_duplicities(pedvars, 0.21)\n",
    "        if len(all_zds) != len(zds) * len(azs) * len(woffs) * len(pedvars) * len(indexs):\n",
    "            raise ValueError(\"Wrong dimensions extracted from IRF cube.\" +  \n",
    "                             \"Probably due to the rounding applied to the IRF coordinates.\")\n",
    "    # If a specific coord_tuple is provided, only extract the IRFs wihin that range of dimensions\n",
    "    else:\n",
    "        if len(coord_tuple) != 5:\n",
    "            raise ValueError(\"coord_tuple needs to contain 5 dimensions, in this order: az, index, pedvar, zd and woff\")\n",
    "        else:\n",
    "            # Get the coordinates to sample:\n",
    "            azs = coord_tuple[0]\n",
    "            indexs = coord_tuple[1]\n",
    "            pedvars = coord_tuple[2]\n",
    "            zds = coord_tuple[3]\n",
    "            woffs = coord_tuple[4]\n",
    "    \n",
    "    print(azs, indexs, pedvars, zds, woffs)\n",
    "    \n",
    "    # For performance, deactivate all branches except the ones needed:\n",
    "    # Also get the entry with max bins to define the binning in energy\n",
    "    effAreaTree.SetBranchStatus(\"*\",0) \n",
    "    if irf_name == 'eff':\n",
    "        effAreaTree.SetBranchStatus(\"e0\",1)\n",
    "        effAreaTree.SetBranchStatus(\"eff\",1)\n",
    "        entry_with_max_bins = find_nearest(all_nbins, all_nbins.max())\n",
    "    elif irf_name == 'Rec_eff':\n",
    "        effAreaTree.SetBranchStatus(\"Rec_e0\",1)\n",
    "        effAreaTree.SetBranchStatus(\"Rec_eff\",1)\n",
    "        entry_with_max_bins = find_nearest(all_rec_nbins, all_rec_nbins.max())\n",
    "    elif irf_name == 'gEffAreaNoTh2MC':\n",
    "        effAreaTree.SetBranchStatus(\"gEffAreaNoTh2MC\",1)\n",
    "        entry_with_max_bins = 0\n",
    "    elif irf_name == 'gEffAreaNoTh2Rec':\n",
    "        effAreaTree.SetBranchStatus(\"gEffAreaNoTh2Rec\",1)\n",
    "        entry_with_max_bins = 0\n",
    "    elif irf_name == 'hEsysMCRelative2D':\n",
    "        effAreaTree.SetBranchStatus(\"hEsysMCRelative2D\",1)\n",
    "        entry_with_max_bins = 0\n",
    "    elif irf_name == 'hAngularDiff_2D':\n",
    "        effAreaTree.SetBranchStatus(\"hAngularDiff_2D\",1)\n",
    "        entry_with_max_bins = 0\n",
    "    else:\n",
    "        raise Exception(\"WrongIrfName\")\n",
    "    # Now we know which entry we need to get in order to have a sample IRF\n",
    "#     sample_irf = sample_energies = []\n",
    "    for i, entry in enumerate(effAreaTree):\n",
    "        if i == entry_with_max_bins:\n",
    "            if irf_name == 'eff':\n",
    "                sample_irf = [j for j in entry.eff]\n",
    "                sample_energies = [j for j in entry.e0]\n",
    "            elif irf_name == 'Rec_eff':\n",
    "                sample_irf = [j for j in entry.Rec_eff]\n",
    "                sample_energies = [j for j in entry.Rec_e0]\n",
    "            elif irf_name == 'gEffAreaNoTh2MC':\n",
    "                sample_irf = graph_to_array_y(entry.gEffAreaNoTh2MC)\n",
    "                sample_energies = graph_to_array_x(entry.gEffAreaNoTh2MC)\n",
    "            elif irf_name == 'gEffAreaNoTh2Rec':\n",
    "                sample_irf = graph_to_array_y(entry.gEffAreaNoTh2Rec)\n",
    "                sample_energies = graph_to_array_x(entry.gEffAreaNoTh2Rec)\n",
    "            elif irf_name == 'hEsysMCRelative2D':\n",
    "                # Migration vs energy bias and true energy\n",
    "                sample_irf, axes = hist2array(entry.hEsysMCRelative2D, return_edges=True)\n",
    "                # Bin edges (one more entry than migra!) for the true energy and \n",
    "                # energy bias (Erec/Etrue)\n",
    "                irf_dimension_1 = bin_edges_to_centers(axes[0])\n",
    "                irf_dimension_2 = bin_edges_to_centers(axes[1])\n",
    "            elif irf_name == 'hEsysMCRelative2DNoDirectionCut':\n",
    "                # Migration vs energy bias and true energy, without direction cut\n",
    "                sample_irf, axes = hist2array(entry.hEsysMCRelative2DNoDirectionCut, return_edges=True)\n",
    "                # Bin edges (one more entry than migra!) for the true energy and \n",
    "                # energy bias (Erec/Etrue)\n",
    "                irf_dimension_1 = bin_edges_to_centers(axes[0])\n",
    "                irf_dimension_2 = bin_edges_to_centers(axes[1])\n",
    "            elif irf_name == 'hAngularDiff_2D':\n",
    "                # PSF vs true energy:\n",
    "                sample_irf, axes = hist2array(entry.hAngularDiff_2D, return_edges=True)\n",
    "                # Bin edges (one more entry than migra!) for the true energy and \n",
    "                # energy bias (Erec/Etrue)\n",
    "                irf_dimension_1 = bin_edges_to_centers(axes[0])\n",
    "                irf_dimension_2 = bin_edges_to_centers(axes[1])\n",
    "                print(irf_dimension_1, irf_dimension_2)\n",
    "                print(\"Length: \", len(irf_dimension_1), len(irf_dimension_2))\n",
    "            else:\n",
    "                raise Exception(\"WrongIrfName\")\n",
    "        if i > entry_with_max_bins:\n",
    "            break\n",
    "    # Create data container, filled with zeros, containing the required dimensions to store\n",
    "    # the IRF for a given coord_tuple. Separated between 1 and 2 dimensions:\n",
    "    if (irf_name == \"hEsysMCRelative2D\" or irf_name == \"hEsysMCRelative2DNoDirectionCut\" or \n",
    "            irf_name == \"hAngularDiff_2D\"):\n",
    "        data = np.zeros((len(irf_dimension_1), len(irf_dimension_2), len(azs), len(indexs), len(pedvars), len(zds), len(woffs)))\n",
    "    else:\n",
    "        data = np.zeros((len(sample_irf), len(azs), len(indexs), len(pedvars), len(zds), len(woffs)))\n",
    "    # Iterate over all IRFs within the file. If the entry i is close to the coordinates within\n",
    "    # the coord_tuple, then store.\n",
    "    for i, entry in enumerate(effAreaTree):\n",
    "        if i%5000 == 0:\n",
    "            print(\"{}/{}\".format(i, len(all_zds)))\n",
    "#         if i == 3239:\n",
    "#             print([j for j in entry.Rec_e0])\n",
    "        # Parameters within the effective area files show some fluctuation, therefore \n",
    "        # we need to use the \"isclose\".\n",
    "        if (np.isclose(azs, all_azs[i], atol=0.01).any() and\n",
    "                np.isclose(indexs, all_indexs[i], atol=0.01).any() and\n",
    "                np.isclose(pedvars, all_pedvars[i], atol=0.21).any() and\n",
    "                np.isclose(zds, all_zds[i], atol=2.1).any() and\n",
    "                np.isclose(woffs, all_Woffs[i], atol=0.05).any()):\n",
    "            if irf_name == 'eff':\n",
    "                irf = [j for j in entry.eff]\n",
    "                energies = [j for j in entry.e0]\n",
    "            elif irf_name == 'Rec_eff':\n",
    "                irf = [j for j in entry.Rec_eff]\n",
    "                energies = [j for j in entry.Rec_e0]\n",
    "            elif irf_name == 'gEffAreaNoTh2MC':\n",
    "                irf = graph_to_array_y(entry.gEffAreaNoTh2MC)\n",
    "                energies = graph_to_array_x(entry.gEffAreaNoTh2MC)\n",
    "            elif irf_name == 'gEffAreaNoTh2Rec':\n",
    "                irf = graph_to_array_y(entry.gEffAreaNoTh2Rec)\n",
    "                energies = graph_to_array_x(entry.gEffAreaNoTh2Rec)\n",
    "            elif irf_name == 'hEsysMCRelative2D':\n",
    "                irf = hist2array(entry.hEsysMCRelative2D)\n",
    "            elif irf_name == 'hEsysMCRelative2DNoDirectionCut':\n",
    "                irf = hist2array(entry.hEsysMCRelative2DNoDirectionCut)\n",
    "            elif irf_name == 'hAngularDiff_2D':\n",
    "                irf = hist2array(entry.hAngularDiff_2D)\n",
    "            else:\n",
    "                raise Exception(\"WrongIrfName\")\n",
    "            # We separate now 1D and 2D irfs:\n",
    "            # 2D IRFs:\n",
    "            if (irf_name == \"hEsysMCRelative2D\" or irf_name == \"hEsysMCRelative2DNoDirectionCut\" or \n",
    "                    irf_name == \"hAngularDiff_2D\"):\n",
    "                if np.shape(irf) == np.shape(sample_irf):\n",
    "                    try:\n",
    "                        data[:,:, find_nearest(azs, all_azs[i]), find_nearest(indexs, all_indexs[i]), find_nearest(pedvars, all_pedvars[i]), \n",
    "                             find_nearest(zds, all_zds[i]), find_nearest(woffs, all_Woffs[i])] = irf\n",
    "                    except:\n",
    "                        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                        print(\"Entry number \", i)\n",
    "                        raise\n",
    "                else:\n",
    "                    print(\"2D IRFs of variable size...\")\n",
    "                    raise\n",
    "            else:\n",
    "                # 1D IRFs:\n",
    "                # In case the extracted IRF has less bins than the \"sample\" one, pad it with zeros:\n",
    "                if len(irf) < len(sample_irf):\n",
    "                    new_irf = np.zeros(len(sample_energies))\n",
    "                    for j, ener in enumerate(energies):\n",
    "                        new_irf[find_nearest(sample_energies, ener)] = irf[j]\n",
    "                    irf = new_irf\n",
    "                try:\n",
    "                    data[:, find_nearest(azs, all_azs[i]), find_nearest(indexs, all_indexs[i]), find_nearest(pedvars, all_pedvars[i]), \n",
    "                         find_nearest(zds, all_zds[i]), find_nearest(woffs, all_Woffs[i])] = irf\n",
    "                except:\n",
    "                    print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                    print(\"Entry number \", i)\n",
    "                    print(energies, irf)\n",
    "                    raise \n",
    "    if return_irf_axes:\n",
    "        if (irf_name == \"hEsysMCRelative2D\" or irf_name == \"hEsysMCRelative2DNoDirectionCut\" or \n",
    "                irf_name == \"hAngularDiff_2D\"):\n",
    "            return data, [np.array(irf_dimension_1), np.array(irf_dimension_2), azs, indexs, pedvars, zds, woffs]\n",
    "        else:\n",
    "            return data, [np.array(sample_energies), azs, indexs, pedvars, zds, woffs]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "def duplicate_dimension(data, axis):\n",
    "    # This function duplicates a single axis, assuming it's length is 1.\n",
    "    current_shape = np.shape(data)\n",
    "    corrected_shape = [2 if i == axis else k for i, k in enumerate(current_shape)]\n",
    "    print(current_shape, corrected_shape)\n",
    "    new_data = np.zeros(corrected_shape)\n",
    "    sl = slice(None, None, None)\n",
    "    new_data[[0 if i == axis else sl for i, k in enumerate(current_shape)]] = \\\n",
    "        data[[0 if i == axis else sl for i, k in enumerate(current_shape)]]\n",
    "    new_data[[1 if i == axis else sl for i, k in enumerate(current_shape)]] = \\\n",
    "        data[[0 if i == axis else sl for i, k in enumerate(current_shape)]]\n",
    "    return new_data\n",
    "\n",
    "\n",
    "def duplicate_dimensions(data):\n",
    "    # This function duplicates all axes, one by one, when their size is 1.\n",
    "    new_data = data\n",
    "    current_shape = np.shape(new_data)\n",
    "    for i, dim in enumerate(current_shape):\n",
    "        if (dim == 1):\n",
    "            new_data = duplicate_dimension(new_data, i)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the current class to be used for the IRF interpolator. We probably need to add more checks, for instance that the coordinate the user tries to interpolate is within the coordinate \"space\" within the effective area file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current IRF interpolator has this shape:\n",
    "* Inputs:\n",
    "    * Effective area file, containing all IRFs in the form $A_{i,j,k,l,m}$ where A can be any IRF and $i..m$ the dimensions within the file. Each IRF within the file has a coordinate $X = [x_i, x_j, x_k, x_l, x_m]$, a point in the 5D \"hyper cube\" of IRFs, to be used in the interpolation.\n",
    "\n",
    "The dimensions are (used in this order):\n",
    "        * Azimuth\n",
    "        * Power-law index\n",
    "        * Pedestal variance\n",
    "        * Zenith\n",
    "        * Camera offset (Woff)\n",
    "* The steps performed are:\n",
    "    * First read the IRF file: \n",
    "        * Load range of all available dimensions $[D_{min}, ..., D_{max}]_{i,j,k,l,m}$ within the file (points corresponding to each IRF)\n",
    "        * Load a 5D cube of a given IRF, as a function of all dimensions \n",
    "    * TO BE IMPLEMENTED: Check if $X \\in D$. If yes, continue. If not... New IRFs need to be computed.\n",
    "    * Interpolate the IRF\n",
    "        * Input: the 5D coordinate to be interpolated\n",
    "        * Returns: the content of the irf (can be 1D or 2D) and the axes (currently just the values, should add more information, probably in the form of a dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrfInterpolator:\n",
    "    def __init__(self, filename):\n",
    "        self.implemented_irf_names_1d = ['eff', 'Rec_eff', 'gEffAreaNoTh2MC', 'gEffAreaNoTh2Rec']\n",
    "        self.implemented_irf_names_2d = ['hEsysMCRelative2D', 'hEsysMCRelative2DNoDirectionCut', 'hAngularDiff_2D']\n",
    "        self.irf_name = \"\"\n",
    "        import os.path\n",
    "        if os.path.isfile(filename):\n",
    "            self.filename = filename\n",
    "        else:\n",
    "            raise FileNotFoundError\n",
    "\n",
    "    def set_irf(self, irf_name):\n",
    "        if irf_name in self.implemented_irf_names_1d or irf_name in self.implemented_irf_names_2d:\n",
    "            self.irf_name = irf_name\n",
    "            self.__load_irf()\n",
    "        else:\n",
    "            print(\"The irf you entered: {}  is either wrong or not implemented.\".format(irf_name))\n",
    "            raise WrongIrf\n",
    "\n",
    "    def __load_irf(self):\n",
    "        irf_data, irf_axes = extract_irf(self.filename, self.irf_name, return_irf_axes=True)\n",
    "        # This is an important technical step: the regular grid interpolator does not accept \n",
    "        # interpolating on a dimension with size = 1.\n",
    "        # Make sure that there are no size 1 dimensions. Do the same with the axes:\n",
    "        irf_data = duplicate_dimensions(irf_data)\n",
    "        # Also the coordinates of the axes need to be in increasing order.\n",
    "        for i, axis in enumerate(irf_axes):\n",
    "            if len(axis) == 1:\n",
    "                irf_axes[i] = np.concatenate((axis.flatten(), axis.flatten() + 0.01), axis=None)\n",
    "        self.irf_data = irf_data\n",
    "        self.irf_axes = irf_axes\n",
    "        self.interpolator = RegularGridInterpolator(self.irf_axes, self.irf_data)\n",
    "\n",
    "    def interpolate(self, coordinate):\n",
    "        # The interpolation is slightly different for 1D or 2D IRFs. We do both cases separated:\n",
    "        if self.irf_name in self.implemented_irf_names_2d:\n",
    "            # In this case, the interpolator needs to interpolate over 2 dimensions:\n",
    "            xx, yy = np.meshgrid(self.irf_axes[0], self.irf_axes[1])\n",
    "            interpolated_irf = self.interpolator((xx, yy, coordinate[0], coordinate[1], coordinate[2],\n",
    "                                                  coordinate[3], coordinate[4]))\n",
    "            return interpolated_irf, [self.irf_axes[0], self.irf_axes[1]]\n",
    "        elif self.irf_name in self.implemented_irf_names_1d:\n",
    "            # In this case, the interpolator needs to interpolate only over 1 dimension (true energy):\n",
    "            interpolated_irf = self.interpolator((self.irf_axes[0], coordinate[0], coordinate[1],\n",
    "                                                  coordinate[2], coordinate[3], coordinate[4]))\n",
    "            return interpolated_irf, [self.irf_axes[0]]\n",
    "        else:\n",
    "            print(\"The interpolation of the irf you entered: {}  is either wrong or not implemented.\".format(self.irf_name))\n",
    "            raise WrongIrf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of use: These 2 steps should ideally be done just once, and then perform a serie of interpolations of this given IRF, taking into account that the slowest step is to load the whole 5D cube of IRFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf_generator = IrfInterpolator('../../../eventDisplay/gernot_effarea_test_direction_full_stats.root')\n",
    "irf_generator.set_irf('eff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this step is done, the interpolation is very fast. So for example, let's draw some effective areas as a function of zenith:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "ax = fig.add_subplot(111)\n",
    "for azimuth in np.arange(9):\n",
    "    irf, axis = irf_generator.interpolate([azimuth, 2.5999999, 7.611, 20., 0.5])\n",
    "    ax.plot(axis[0], irf, marker='o', label='Azimuth bin {} deg'.format(azimuth))\n",
    "ax.grid(color='gray', linestyle='-', linewidth=2)\n",
    "ax.set_xlabel('log$_{10}$( Energy) TeV')\n",
    "ax.set_yscale(\"log\", nonposy='clip')\n",
    "ax.set_ylabel('Effective area')\n",
    "ax.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another example, this time a 2D IRF such as the energy bias vs true energy, we do the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# irf_generator = Irf_interpolator('gernot_effarea_test_direction_full_stats.root')\n",
    "irf_generator.set_irf('hEsysMCRelative2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irf, axis = irf_generator.interpolate([0, 2.5999999, 7.611, 20.0, 0.5])\n",
    "fig = plt.figure(figsize=(10,15))\n",
    "plt.imshow(np.flip(irf, axis=0), vmin=irf.min(), vmax=irf.max(),\n",
    "           extent=[axis[0].min(), axis[0].max(), axis[1].min(), axis[1].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always access the values that are contained in the Effective area file (and it's coordinates) after you load them with the 'irf_generator.set_irf()' function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loaded IRF: \", irf_generator.irf_name)\n",
    "print(\"Shape of the IRF hypercube: \", np.shape(irf_generator.irf_data))\n",
    "print(irf_generator.irf_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from pyV2DL3.eventdisplay.IrfInterpolator import IrfInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azimuth = 1.\n",
    "noise= 5.0\n",
    "zenith= 20.\n",
    "offset=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_area_file = 'effArea-v483-auxv01-CARE_June1702-Cut-NTel2-PointSource-Hard-TMVA-BDT-GEO-V6_2012_2013a-ATM61-T1234.root'\n",
    "eff_area_path = '/home/thassan/VERITAS/eventDisplay/v483/sample_effective_area'\n",
    "irf_interpolator = IrfInterpolator(\"{}/{}\".format(eff_area_path, eff_area_file), azimuth)\n",
    "irf_interpolator.set_irf('hAngularLogDiffEmc_2D')\n",
    "eff_area, axis = irf_interpolator.interpolate([noise, zenith, offset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,15))\n",
    "plt.imshow(np.flip(eff_area, axis=0), vmin=eff_area.min(), vmax=eff_area.max(),\n",
    "           extent=[axis[0].min(), axis[0].max(), axis[1].min(), axis[1].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
